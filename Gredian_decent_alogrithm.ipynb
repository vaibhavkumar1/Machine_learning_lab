{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time \n",
    "#Gradient Descent class for linear Regression\n",
    "class GradientDescentLinearRegression:\n",
    "    def _init_(self, learning_rate=0.01, iterations=1000):\n",
    "        self.learning_rate, self.iterations = learning_rate, iterations\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        b0 = 0\n",
    "        b1 = 0\n",
    "        n = X.shape[0]\n",
    "        for _ in range(self.iterations):\n",
    "            b0_deri = np.sum(b1*X + b0 - y) / n\n",
    "            b1_deri = np.sum(X*((b1*X + b0) - y)) / n\n",
    "            b0 = b0 - (self.learning_rate * b0_deri)\n",
    "            b1 = b1 - (self.learning_rate * b1_deri)\n",
    "        self.b1, self.b0 = b1, b0\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.b1*X + self.b0\n",
    "    \n",
    "    def rmse(self, X):# Calculating Root Mean Squares Error\n",
    "        rmse = 0\n",
    "        n = X.shape[0]\n",
    "        #print(n)\n",
    "        for i in range(n):\n",
    "            y_pred = clf.predict(X[i])\n",
    "            rmse += (y_pred - y[i]) ** 2\n",
    "        rmse = np.sqrt(rmse/n)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'headbrain.csv')\n",
    "# Collecting X and Y\n",
    "X = data['Head Size(cm^3)'].values/1000\n",
    "y = data['Brain Weight(grams)'].values/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.512, 3.738, 4.261, 3.777, 4.177, 3.585, 3.785, 3.559, 3.613,\n",
       "       3.982, 3.443, 3.993, 3.64 , 4.208, 3.832, 3.876, 3.497, 3.466,\n",
       "       3.095, 4.424, 3.878, 4.046, 3.804, 3.71 , 4.747, 4.423, 4.036,\n",
       "       4.022, 3.454, 4.175, 3.787, 3.796, 4.103, 4.161, 4.158, 3.814,\n",
       "       3.527, 3.748, 3.334, 3.492, 3.962, 3.505, 4.315, 3.804, 3.863,\n",
       "       4.034, 4.308, 3.165, 3.641, 3.644, 3.891, 3.793, 4.27 , 4.063,\n",
       "       4.012, 3.458, 3.89 , 4.166, 3.935, 3.669, 3.866, 3.393, 4.442,\n",
       "       4.253, 3.727, 3.329, 3.415, 3.372, 4.43 , 4.381, 4.008, 3.858,\n",
       "       4.121, 4.057, 3.824, 3.394, 3.558, 3.362, 3.93 , 3.835, 3.83 ,\n",
       "       3.856, 3.249, 3.577, 3.933, 3.85 , 3.309, 3.406, 3.506, 3.907,\n",
       "       4.16 , 3.318, 3.662, 3.899, 3.7  , 3.779, 3.473, 3.49 , 3.654,\n",
       "       3.478, 3.495, 3.834, 3.876, 3.661, 3.618, 3.648, 4.032, 3.399,\n",
       "       3.916, 4.43 , 3.695, 3.524, 3.571, 3.594, 3.383, 3.499, 3.589,\n",
       "       3.9  , 4.114, 3.937, 3.399, 4.2  , 4.488, 3.614, 4.051, 3.782,\n",
       "       3.391, 3.124, 4.053, 3.582, 3.666, 3.532, 4.046, 3.667, 2.857,\n",
       "       3.436, 3.791, 3.302, 3.104, 3.171, 3.572, 3.53 , 3.175, 3.438,\n",
       "       3.903, 3.899, 3.401, 3.267, 3.451, 3.09 , 3.413, 3.323, 3.68 ,\n",
       "       3.439, 3.853, 3.156, 3.279, 3.707, 4.006, 3.269, 3.071, 3.779,\n",
       "       3.548, 3.292, 3.497, 3.082, 3.248, 3.358, 3.803, 3.566, 3.145,\n",
       "       3.503, 3.571, 3.724, 3.615, 3.203, 3.609, 3.561, 3.979, 3.533,\n",
       "       3.689, 3.158, 4.005, 3.181, 3.479, 3.642, 3.632, 3.069, 3.394,\n",
       "       3.703, 3.165, 3.354, 3.   , 3.687, 3.556, 2.773, 3.058, 3.344,\n",
       "       3.493, 3.297, 3.36 , 3.228, 3.277, 3.851, 3.067, 3.692, 3.402,\n",
       "       3.995, 3.318, 2.72 , 2.937, 3.58 , 2.939, 2.989, 3.586, 3.156,\n",
       "       3.246, 3.17 , 3.268, 3.389, 3.381, 2.864, 3.74 , 3.479, 3.647,\n",
       "       3.716, 3.284, 4.204, 3.735, 3.218, 3.685, 3.704, 3.214, 3.394,\n",
       "       3.233, 3.352, 3.391])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.53 , 1.297, 1.335, 1.282, 1.59 , 1.3  , 1.4  , 1.255, 1.355,\n",
       "       1.375, 1.34 , 1.38 , 1.355, 1.522, 1.208, 1.405, 1.358, 1.292,\n",
       "       1.34 , 1.4  , 1.357, 1.287, 1.275, 1.27 , 1.635, 1.505, 1.49 ,\n",
       "       1.485, 1.31 , 1.42 , 1.318, 1.432, 1.364, 1.405, 1.432, 1.207,\n",
       "       1.375, 1.35 , 1.236, 1.25 , 1.35 , 1.32 , 1.525, 1.57 , 1.34 ,\n",
       "       1.422, 1.506, 1.215, 1.311, 1.3  , 1.224, 1.35 , 1.335, 1.39 ,\n",
       "       1.4  , 1.225, 1.31 , 1.56 , 1.33 , 1.222, 1.415, 1.175, 1.33 ,\n",
       "       1.485, 1.47 , 1.135, 1.31 , 1.154, 1.51 , 1.415, 1.468, 1.39 ,\n",
       "       1.38 , 1.432, 1.24 , 1.195, 1.225, 1.188, 1.252, 1.315, 1.245,\n",
       "       1.43 , 1.279, 1.245, 1.309, 1.412, 1.12 , 1.22 , 1.28 , 1.44 ,\n",
       "       1.37 , 1.192, 1.23 , 1.346, 1.29 , 1.165, 1.24 , 1.132, 1.242,\n",
       "       1.27 , 1.218, 1.43 , 1.588, 1.32 , 1.29 , 1.26 , 1.425, 1.226,\n",
       "       1.36 , 1.62 , 1.31 , 1.25 , 1.295, 1.29 , 1.29 , 1.275, 1.25 ,\n",
       "       1.27 , 1.362, 1.3  , 1.173, 1.256, 1.44 , 1.18 , 1.306, 1.35 ,\n",
       "       1.125, 1.165, 1.312, 1.3  , 1.27 , 1.335, 1.45 , 1.31 , 1.027,\n",
       "       1.235, 1.26 , 1.165, 1.08 , 1.127, 1.27 , 1.252, 1.2  , 1.29 ,\n",
       "       1.334, 1.38 , 1.14 , 1.243, 1.34 , 1.168, 1.322, 1.249, 1.321,\n",
       "       1.192, 1.373, 1.17 , 1.265, 1.235, 1.302, 1.241, 1.078, 1.52 ,\n",
       "       1.46 , 1.075, 1.28 , 1.18 , 1.25 , 1.19 , 1.374, 1.306, 1.202,\n",
       "       1.24 , 1.316, 1.28 , 1.35 , 1.18 , 1.21 , 1.127, 1.324, 1.21 ,\n",
       "       1.29 , 1.1  , 1.28 , 1.175, 1.16 , 1.205, 1.163, 1.022, 1.243,\n",
       "       1.35 , 1.237, 1.204, 1.09 , 1.355, 1.25 , 1.076, 1.12 , 1.22 ,\n",
       "       1.24 , 1.22 , 1.095, 1.235, 1.105, 1.405, 1.15 , 1.305, 1.22 ,\n",
       "       1.296, 1.175, 0.955, 1.07 , 1.32 , 1.06 , 1.13 , 1.25 , 1.225,\n",
       "       1.18 , 1.178, 1.142, 1.13 , 1.185, 1.012, 1.28 , 1.103, 1.408,\n",
       "       1.3  , 1.246, 1.38 , 1.35 , 1.06 , 1.35 , 1.22 , 1.11 , 1.215,\n",
       "       1.104, 1.17 , 1.12 ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GradientDescentLinearRegression' object has no attribute 'iterations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-955b6a311f96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientDescentLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-44ec6893e6cd>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mb0_deri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mb1_deri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GradientDescentLinearRegression' object has no attribute 'iterations'"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    clf = GradientDescentLinearRegression()\n",
    "    clf.fit(X, y)\n",
    "    time.sleep(2)\n",
    "    plt.scatter(X, y, color='black')\n",
    "    plt.plot(X, clf.predict(X))\n",
    "    plt.xlabel('Head Size(cm^3)')  \n",
    "    plt.ylabel('Brain Weight(grams)')  \n",
    "  \n",
    "    #displaying the title \n",
    "    plt.title(\"Gradient Descent Linear Regressor\")\n",
    "    plt.show()\n",
    "    # Calculating Root Mean Squares Error\n",
    "    rmse = clf.rmse(X)\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "clf.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_iter must be > zero. Got 0.000000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-52993e2b124a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"hinge\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loss, penalty, alpha, l1_ratio, fit_intercept, max_iter, tol, shuffle, verbose, epsilon, n_jobs, random_state, learning_rate, eta0, power_t, early_stopping, validation_fraction, n_iter_no_change, class_weight, warm_start, average)\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             warm_start=warm_start, average=average)\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loss, penalty, alpha, l1_ratio, fit_intercept, max_iter, tol, shuffle, verbose, epsilon, n_jobs, random_state, learning_rate, eta0, power_t, early_stopping, validation_fraction, n_iter_no_change, class_weight, warm_start, average)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_fraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iter_no_change\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             average=average)\n\u001b[0m\u001b[0;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loss, penalty, alpha, C, l1_ratio, fit_intercept, max_iter, tol, shuffle, verbose, epsilon, random_state, learning_rate, eta0, power_t, early_stopping, validation_fraction, n_iter_no_change, warm_start, average)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# current tests expect init to do parameter validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# but we are not allowed to set attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_validate_params\u001b[1;34m(self, for_partial_fit)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"early_stopping should be False with partial_fit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_iter must be > zero. Got %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"l1_ratio must be in [0, 1]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max_iter must be > zero. Got 0.000000"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
